{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xianfanwindy/Ultralytics_Solutions/blob/main/notebooks/how-to-track-the-objects-in-zone-using-ultralytics-yolo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6MPjfT5NrKQ"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "  <a href=\"https://ultralytics.com/yolo\" target=\"_blank\">\n",
        "    <img width=\"1024\", src=\"https://raw.githubusercontent.com/ultralytics/assets/main/yolov8/banner-yolov8.png\"></a>\n",
        "\n",
        "  [‰∏≠Êñá](https://docs.ultralytics.com/zh/) | [ÌïúÍµ≠Ïñ¥](https://docs.ultralytics.com/ko/) | [Êó•Êú¨Ë™û](https://docs.ultralytics.com/ja/) | [–†—É—Å—Å–∫–∏–π](https://docs.ultralytics.com/ru/) | [Deutsch](https://docs.ultralytics.com/de/) | [Fran√ßais](https://docs.ultralytics.com/fr/) | [Espa√±ol](https://docs.ultralytics.com/es/) | [Portugu√™s](https://docs.ultralytics.com/pt/) | [T√ºrk√ße](https://docs.ultralytics.com/tr/) | [Ti·∫øng Vi·ªát](https://docs.ultralytics.com/vi/) | [ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](https://docs.ultralytics.com/ar/)\n",
        "\n",
        "  <a href=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml\"><img src=\"https://github.com/ultralytics/ultralytics/actions/workflows/ci.yml/badge.svg\" alt=\"Ultralytics CI\"></a>\n",
        "  <a href=\"https://colab.research.google.com/github/ultralytics/notebooks/blob/main/notebooks/how-to-track-the-objects-in-zone-using-ultralytics-yolo.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
        "  \n",
        "  <a href=\"https://ultralytics.com/discord\"><img alt=\"Discord\" src=\"https://img.shields.io/discord/1089800235347353640?logo=discord&logoColor=white&label=Discord&color=blue\"></a>\n",
        "  <a href=\"https://community.ultralytics.com\"><img alt=\"Ultralytics Forums\" src=\"https://img.shields.io/discourse/users?server=https%3A%2F%2Fcommunity.ultralytics.com&logo=discourse&label=Forums&color=blue\"></a>\n",
        "  <a href=\"https://reddit.com/r/ultralytics\"><img alt=\"Ultralytics Reddit\" src=\"https://img.shields.io/reddit/subreddit-subscribers/ultralytics?style=flat&logo=reddit&logoColor=white&label=Reddit&color=blue\"></a>\n",
        "  \n",
        "  Welcome to the Object tracking in zones using Ultralytics YOLO11 üöÄ notebook! <a href=\"https://github.com/ultralytics/ultralytics\">YOLO11</a> is the latest version of the YOLO (You Only Look Once) AI models developed by <a href=\"https://ultralytics.com\">Ultralytics</a>. We hope that the resources in this notebook will help you get the most out of YOLO11. Please browse the YOLO11 <a href=\"https://docs.ultralytics.com/\">Docs</a> for details, raise an issue on <a href=\"https://github.com/ultralytics/ultralytics\">GitHub</a> for support, and join our <a href=\"https://ultralytics.com/discord\">Discord</a> community for questions and discussions!</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TrackZone using Ultralytics YOLO11\n",
        "\n",
        "This notebook serves as a starting point for [tracking objects in zones](https://docs.ultralytics.com/guides/trackzone/) in videos or live streams using the YOLO11 model.\n",
        "\n",
        "### What is TrackZone?\n",
        "\n",
        "TrackZone specializes in monitoring objects within designated areas of a frame instead of the whole frame. Built on [Ultralytics YOLO11](https://github.com/ultralytics/ultralytics/), it integrates object detection and tracking specifically within zones for videos and live camera feeds. YOLO11's advanced algorithms and [deep learning](https://www.ultralytics.com/glossary/deep-learning-dl) technologies make it a perfect choice for real-time use cases, offering precise and efficient object tracking in applications like crowd monitoring and surveillance.\n",
        "\n",
        "### Advantages of Object Tracking in Zones (TrackZone)\n",
        "\n",
        "- **Targeted Analysis:** Tracking objects within specific zones allows for more focused insights, enabling precise monitoring and analysis of areas of interest, such as entry points or restricted zones.\n",
        "- **Improved Efficiency:** By narrowing the tracking scope to defined zones, TrackZone reduces computational overhead, ensuring faster processing and optimal performance.\n",
        "- **Enhanced Security:** Zonal tracking improves surveillance by monitoring critical areas, aiding in the early detection of unusual activity or security breaches.\n",
        "- **Scalable Solutions:** The ability to focus on specific zones makes TrackZone adaptable to various scenarios, from retail spaces to industrial settings, ensuring seamless integration and scalability."
      ],
      "metadata": {
        "id": "7EM2nwU4jshF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "### Setup\n",
        "\n",
        "pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware.\n",
        "\n",
        "[![PyPI - Version](https://img.shields.io/pypi/v/ultralytics?logo=pypi&logoColor=white)](https://pypi.org/project/ultralytics/) [![Downloads](https://static.pepy.tech/badge/ultralytics)](https://www.pepy.tech/projects/ultralytics) [![PyPI - Python Version](https://img.shields.io/pypi/pyversions/ultralytics?logo=python&logoColor=gold)](https://pypi.org/project/ultralytics/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "outputId": "aedcb6d0-505c-4512-b1f4-88983d7f6ad2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install ultralytics\n",
        "\n",
        "import ultralytics\n",
        "import cv2\n",
        "from ultralytics.utils.downloads import safe_download\n",
        "from ultralytics import solutions\n",
        "\n",
        "ultralytics.checks()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.170 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete ‚úÖ (2 CPUs, 12.7 GB RAM, 42.2/112.6 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read the Video File\n",
        "\n",
        "- You can either read the video file directly or stream the content from an RTSP (Real-Time Streaming Protocol) source, allowing for flexible video input depending on your needs.\n",
        "- We will also set up the video writer to handle the output video writing."
      ],
      "metadata": {
        "id": "h8go3HNgN0WU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "safe_download(\"https://github.com/ultralytics/notebooks/releases/download/v0.0.0/solutions-ci-demo.mp4\")\n",
        "cap = cv2.VideoCapture(\"solutions-ci-demo.mp4\")\n",
        "assert cap.isOpened(), \"Error reading video file\"\n",
        "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH,\n",
        "                                       cv2.CAP_PROP_FRAME_HEIGHT,\n",
        "                                       cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Video writer\n",
        "video_writer = cv2.VideoWriter(\"trackzone.avi\",\n",
        "                               cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
        "                               fps, (w, h))"
      ],
      "metadata": {
        "id": "QUgMYUvlNLvy",
        "outputId": "4982a4ca-6790-46f3-edfa-0a665952fa9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/notebooks/releases/download/v0.0.0/solutions-ci-demo.mp4 to 'solutions-ci-demo.mp4'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 265k/265k [00:00<00:00, 20.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Region Coordinates\n",
        "\n",
        "Here, we set the coordinates for specific regions to ensure accurate object tracking and analysis within the video or stream. This helps monitor and track objects effectively in different areas."
      ],
      "metadata": {
        "id": "3wJlBXORXNsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define region points\n",
        "# region_points = [(20, 400), (1080, 400)]  # For line tracking\n",
        "region_points = [(20, 400), (1080, 400), (1080, 360), (20, 360)]  # For rectangle region tracking\n",
        "# region_points = [(20, 400), (1080, 400), (1080, 360), (20, 360), (20, 400)]  # For polygon region tracking"
      ],
      "metadata": {
        "id": "bVCrrForXRgS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize the TrackZone Class\n",
        "\n",
        "- Next, let's initialize the `TrackZone` class to track objects in each frame of the video."
      ],
      "metadata": {
        "id": "rt3soEHzXe8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Init TrackZone (Object Tracking in Zones, not complete frame)\n",
        "trackzone = solutions.TrackZone(\n",
        "    show=True,  # Display the output\n",
        "    region=region_points,  # Pass region points\n",
        "    model=\"yolo11n.pt\",  # You can use any model that Ultralytics support, i.e. YOLOv9, YOLOv10\n",
        "    # line_width=2,  # Adjust the line width for bounding boxes and text display\n",
        "    # classes=[0, 2],  # If you want to track specific classes i.e. person and car with COCO pretrained model.\n",
        ")"
      ],
      "metadata": {
        "id": "Va24DpUZXTh3",
        "outputId": "1fc4bec1-cb06-4efd-b5fd-c7ced3457128",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics Solutions: ‚úÖ {'source': None, 'model': 'yolo11n.pt', 'classes': None, 'show_conf': True, 'show_labels': True, 'region': [(20, 400), (1080, 400), (1080, 360), (20, 360)], 'colormap': 21, 'show_in': True, 'show_out': True, 'up_angle': 145.0, 'down_angle': 90, 'kpts': [6, 8, 10], 'analytics_type': 'line', 'figsize': (12.8, 7.2), 'blur_ratio': 0.5, 'vision_point': (20, 20), 'crop_dir': 'cropped-detections', 'json_file': None, 'line_width': 2, 'records': 5, 'fps': 30.0, 'max_hist': 5, 'meter_per_pixel': 0.05, 'max_speed': 120, 'show': True, 'iou': 0.7, 'conf': 0.25, 'device': None, 'max_det': 300, 'half': False, 'tracker': 'botsort.yaml', 'verbose': True, 'data': 'images'}\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.35M/5.35M [00:00<00:00, 134MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING ‚ö†Ô∏è Environment does not support cv2.imshow() or PIL Image.show()\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process Video Frames\n",
        "\n",
        "In this step, we will process each frame of the video to detect and analyze objects. This allows for real-time tracking, based on the visual data in the frames."
      ],
      "metadata": {
        "id": "1ewYRFFqXvtj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Process video\n",
        "while cap.isOpened():\n",
        "    success, im0 = cap.read()\n",
        "    if not success:\n",
        "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
        "        break\n",
        "    results = trackzone(im0)  # track the objects\n",
        "    video_writer.write(results.plot_im)   # write the video frames\n",
        "\n",
        "cap.release()   # Release the capture\n",
        "video_writer.release()"
      ],
      "metadata": {
        "id": "PVf1pyRtXijz",
        "outputId": "e77c7965-de34-403c-d84b-4e9719f8d733",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['lap>=0.5.12'] not found, attempting AutoUpdate...\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 0.6s\n",
            "WARNING ‚ö†Ô∏è \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "0: 360x640 18.3ms\n",
            "Speed: 11047.8ms track, 18.3ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "1: 360x640 4.0ms\n",
            "Speed: 22.5ms track, 4.0ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "2: 360x640 6.6ms\n",
            "Speed: 20.7ms track, 6.6ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "3: 360x640 4.1ms\n",
            "Speed: 16.5ms track, 4.1ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "4: 360x640 2.9ms\n",
            "Speed: 19.8ms track, 2.9ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "5: 360x640 4.1ms\n",
            "Speed: 16.4ms track, 4.1ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "6: 360x640 4.3ms\n",
            "Speed: 15.7ms track, 4.3ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "7: 360x640 4.6ms\n",
            "Speed: 18.1ms track, 4.6ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "8: 360x640 3.6ms\n",
            "Speed: 20.7ms track, 3.6ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "9: 360x640 3.5ms\n",
            "Speed: 22.3ms track, 3.5ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "10: 360x640 7.7ms\n",
            "Speed: 24.0ms track, 7.7ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "11: 360x640 3.4ms\n",
            "Speed: 21.2ms track, 3.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "12: 360x640 3.1ms\n",
            "Speed: 20.5ms track, 3.1ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "13: 360x640 3.7ms\n",
            "Speed: 17.2ms track, 3.7ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "14: 360x640 3.2ms\n",
            "Speed: 18.8ms track, 3.2ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "15: 360x640 4.8ms\n",
            "Speed: 21.7ms track, 4.8ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "16: 360x640 5.3ms\n",
            "Speed: 20.5ms track, 5.3ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "17: 360x640 5.4ms\n",
            "Speed: 22.0ms track, 5.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "18: 360x640 4.1ms\n",
            "Speed: 21.9ms track, 4.1ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "19: 360x640 5.1ms\n",
            "Speed: 21.8ms track, 5.1ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "20: 360x640 3.6ms\n",
            "Speed: 21.3ms track, 3.6ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "21: 360x640 3.5ms\n",
            "Speed: 21.4ms track, 3.5ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "22: 360x640 3.2ms\n",
            "Speed: 21.6ms track, 3.2ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "23: 360x640 4.2ms\n",
            "Speed: 13.1ms track, 4.2ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "24: 360x640 4.3ms\n",
            "Speed: 13.2ms track, 4.3ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "25: 360x640 4.1ms\n",
            "Speed: 13.0ms track, 4.1ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "26: 360x640 3.2ms\n",
            "Speed: 12.9ms track, 3.2ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "27: 360x640 2.9ms\n",
            "Speed: 12.7ms track, 2.9ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "28: 360x640 3.0ms\n",
            "Speed: 12.3ms track, 3.0ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "29: 360x640 3.1ms\n",
            "Speed: 13.4ms track, 3.1ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "30: 360x640 3.4ms\n",
            "Speed: 13.0ms track, 3.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "31: 360x640 3.6ms\n",
            "Speed: 13.2ms track, 3.6ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "32: 360x640 3.1ms\n",
            "Speed: 12.9ms track, 3.1ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "33: 360x640 3.4ms\n",
            "Speed: 12.7ms track, 3.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "34: 360x640 3.2ms\n",
            "Speed: 12.5ms track, 3.2ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "35: 360x640 3.6ms\n",
            "Speed: 19.0ms track, 3.6ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "36: 360x640 2.9ms\n",
            "Speed: 19.2ms track, 2.9ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "37: 360x640 2.7ms\n",
            "Speed: 12.2ms track, 2.7ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "38: 360x640 3.2ms\n",
            "Speed: 12.6ms track, 3.2ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "39: 360x640 3.3ms\n",
            "Speed: 20.8ms track, 3.3ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "40: 360x640 4.7ms\n",
            "Speed: 17.1ms track, 4.7ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "41: 360x640 3.7ms\n",
            "Speed: 13.4ms track, 3.7ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "42: 360x640 3.1ms\n",
            "Speed: 12.3ms track, 3.1ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "43: 360x640 2.8ms\n",
            "Speed: 12.2ms track, 2.8ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "44: 360x640 3.0ms\n",
            "Speed: 11.7ms track, 3.0ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "45: 360x640 2.6ms\n",
            "Speed: 11.6ms track, 2.6ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "46: 360x640 3.1ms\n",
            "Speed: 11.7ms track, 3.1ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "47: 360x640 2.7ms\n",
            "Speed: 12.7ms track, 2.7ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "48: 360x640 2.8ms\n",
            "Speed: 12.7ms track, 2.8ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "49: 360x640 2.9ms\n",
            "Speed: 12.4ms track, 2.9ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "50: 360x640 2.9ms\n",
            "Speed: 14.5ms track, 2.9ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "51: 360x640 3.1ms\n",
            "Speed: 12.0ms track, 3.1ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "52: 360x640 2.8ms\n",
            "Speed: 11.3ms track, 2.8ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "53: 360x640 2.4ms\n",
            "Speed: 10.9ms track, 2.4ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "54: 360x640 2.9ms\n",
            "Speed: 16.6ms track, 2.9ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "55: 360x640 2.9ms\n",
            "Speed: 11.1ms track, 2.9ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "56: 360x640 2.8ms\n",
            "Speed: 12.5ms track, 2.8ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "57: 360x640 2.8ms\n",
            "Speed: 11.0ms track, 2.8ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "58: 360x640 2.3ms\n",
            "Speed: 12.2ms track, 2.3ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "59: 360x640 2.3ms\n",
            "Speed: 10.9ms track, 2.3ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "60: 360x640 2.8ms\n",
            "Speed: 11.9ms track, 2.8ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "WARNING ‚ö†Ô∏è no tracks found!\n",
            "61: 360x640 2.2ms\n",
            "Speed: 11.6ms track, 2.2ms solution per image at shape (1, 3, 360, 640)\n",
            "\n",
            "Video frame is empty or video processing has been successfully completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Plants Tracking in Field Using Ultralytics YOLO11](https://github.com/ultralytics/docs/releases/download/0/plants-tracking-in-zone-using-ultralytics-yolo11.avif)"
      ],
      "metadata": {
        "id": "bWskbLSKH2S5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwBUa5kZyZ2k"
      },
      "source": [
        "Crafted with üíô by [Ultralytics](https://ultralytics.com/)  \n",
        "\n",
        "üåü Explore and star the [Ultralytics Notebooks](https://github.com/ultralytics/notebooks/) to supercharge your AI journey! üöÄ"
      ]
    }
  ]
}